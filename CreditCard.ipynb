{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.3.1-cp312-cp312-win_amd64.whl.metadata (26 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\dt user2\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\dt user2\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.12.1)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dt user2\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.2)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached fsspec-2024.6.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting mkl<=2021.4.0,>=2021.1.1 (from torch)\n",
      "  Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\dt user2\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\dt user2\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dt user2\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in c:\\users\\dt user2\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Using cached torch-2.3.1-cp312-cp312-win_amd64.whl (159.7 MB)\n",
      "Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl (228.5 MB)\n",
      "Using cached filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Using cached fsspec-2024.6.0-py3-none-any.whl (176 kB)\n",
      "Using cached networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "Installing collected packages: networkx, mkl, fsspec, filelock, torch\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 32] The process cannot access the file because it is being used by another process: 'c:\\\\Users\\\\DT User2\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\Lib\\\\site-packages\\\\networkx\\\\classes\\\\filters.py'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
      "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
      "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
      "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
      "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
      "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
      "\n",
      "        V26       V27       V28  Amount  Class  \n",
      "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
      "1  0.125895 -0.008983  0.014724    2.69      0  \n",
      "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
      "3 -0.221929  0.062723  0.061458  123.50      0  \n",
      "4  0.502292  0.219422  0.215153   69.99      0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "data = pd.read_csv(r'C:\\Users\\DT User2\\Desktop\\creditcard.csv')\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time      0\n",
      "V1        0\n",
      "V2        0\n",
      "V3        0\n",
      "V4        0\n",
      "V5        0\n",
      "V6        0\n",
      "V7        0\n",
      "V8        0\n",
      "V9        0\n",
      "V10       0\n",
      "V11       0\n",
      "V12       0\n",
      "V13       0\n",
      "V14       0\n",
      "V15       0\n",
      "V16       0\n",
      "V17       0\n",
      "V18       0\n",
      "V19       0\n",
      "V20       0\n",
      "V21       0\n",
      "V22       0\n",
      "V23       0\n",
      "V24       0\n",
      "V25       0\n",
      "V26       0\n",
      "V27       0\n",
      "V28       0\n",
      "Amount    0\n",
      "Class     0\n",
      "dtype: int64\n",
      "Class\n",
      "0    284315\n",
      "1       492\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())\n",
    "\n",
    "print(data['Class'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y.to_numpy(), dtype=torch.float32)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(30, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(10, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 30),\n",
    "            nn.Sigmoid()  \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "model = Autoencoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.8691\n",
      "Epoch [2/20], Loss: 0.8033\n",
      "Epoch [3/20], Loss: 0.7934\n",
      "Epoch [4/20], Loss: 0.7893\n",
      "Epoch [5/20], Loss: 0.7871\n",
      "Epoch [6/20], Loss: 0.7853\n",
      "Epoch [7/20], Loss: 0.7841\n",
      "Epoch [8/20], Loss: 0.7830\n",
      "Epoch [9/20], Loss: 0.7821\n",
      "Epoch [10/20], Loss: 0.7802\n",
      "Epoch [11/20], Loss: 0.7792\n",
      "Epoch [12/20], Loss: 0.7783\n",
      "Epoch [13/20], Loss: 0.7771\n",
      "Epoch [14/20], Loss: 0.7759\n",
      "Epoch [15/20], Loss: 0.7730\n",
      "Epoch [16/20], Loss: 0.7717\n",
      "Epoch [17/20], Loss: 0.7709\n",
      "Epoch [18/20], Loss: 0.7703\n",
      "Epoch [19/20], Loss: 0.7699\n",
      "Epoch [20/20], Loss: 0.7696\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_data, _ in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_data)\n",
    "        loss = criterion(outputs, batch_data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * batch_data.size(0)\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {train_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.7565\n",
      "Number of detected anomalies: 2849\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss = 0\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch_data, _ in test_loader:\n",
    "        reconstructions = model(batch_data)\n",
    "        loss = criterion(reconstructions, batch_data)\n",
    "        test_loss += loss.item() * batch_data.size(0)\n",
    "        predictions.extend(reconstructions)\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "\n",
    "predictions = torch.stack(predictions).numpy()\n",
    "\n",
    "reconstruction_errors = np.linalg.norm(X_test.numpy() - predictions, axis=1)\n",
    "\n",
    "threshold = np.percentile(reconstruction_errors, 95)\n",
    "\n",
    "anomalies = reconstruction_errors > threshold\n",
    "\n",
    "print(f'Number of detected anomalies: {anomalies.sum()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[54104  2760]\n",
      " [    9    89]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.95      0.98     56864\n",
      "         1.0       0.03      0.91      0.06        98\n",
      "\n",
      "    accuracy                           0.95     56962\n",
      "   macro avg       0.52      0.93      0.52     56962\n",
      "weighted avg       1.00      0.95      0.97     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test.numpy(), anomalies))\n",
    "print(classification_report(y_test.numpy(), anomalies))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
